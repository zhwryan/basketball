# -*- coding: utf-8 -*-
# https://platform.openai.com/docs/api-reference

import os

# 配置推理模型
REASONER_MODELS = {
    "deepseek-r1-distill-llama-70b": True,
    "deepseek-r1:8b": True,
    "deepseek-r1:14b": True,
    "deepseek-reasoner": True,
    "deepseek-r1-distill-qwen-7b": True,
    "deepseek-r1-distill-qwen-32b": True,
    "deepseek-ai/DeepSeek-R1": True,
    "Pro/deepseek-ai/DeepSeek-R1": True,
    "deepseek-ai/deepseek-r1": True,
    "deepseek-r1-250120": True,
}

# 配置模型
LLM_CONFIGS = {}

LLM_CONFIGS["qwen"] = {
    "base_url":
    "https://dashscope.aliyuncs.com/compatible-mode/v1",
    "api_key":
    os.getenv("QWEN_ACCESS_KEY"),
    'models': [
        'deepseek-v3',
        'deepseek-r1',
        'deepseek-r1-distill-llama-70b',
        'deepseek-r1-distill-qwen-32b',
        'deepseek-r1-distill-qwen-14b',
        'deepseek-r1-distill-llama-8b',
        'deepseek-r1-distill-qwen-1.5b',
        'deepseek-r1-distill-qwen-7b',
        'qwen1.5-7b-chat',
        'qwen-vl-ocr-latest',
        'qwen-vl-ocr',
        'qwen-coder-plus-1106',
        'qwen-coder-plus',
        'qwen-coder-plus-latest',
        'qwen2.5-coder-3b-instruct',
        'qwen2.5-coder-0.5b-instruct',
        'qwen2.5-coder-14b-instruct',
        'qwen2.5-coder-32b-instruct',
        'qwen-coder-turbo-0919',
        'qwen2.5-0.5b-instruct',
        'qwen2.5-1.5b-instruct',
        'qwen2.5-3b-instruct',
        'qwen2.5-7b-instruct',
        'qwen2.5-14b-instruct',
        'qwen2.5-32b-instruct',
        'qwen2.5-72b-instruct',
        'qwen2.5-coder-7b-instruct',
        'qwen2.5-math-1.5b-instruct',
        'qwen2.5-math-7b-instruct',
        'qwen2.5-math-72b-instruct',
        'qwen-turbo-0919',
        'qwen-turbo-latest',
        'qwen-plus-0919',
        'qwen-plus-latest',
        'qwen-max-0919',
        'qwen-max-latest',
        'qwen-coder-turbo',
        'qwen-coder-turbo-latest',
        'qwen-math-turbo-0919',
        'qwen-math-turbo',
        'qwen-math-turbo-latest',
        'qwen-math-plus-0919',
        'qwen-math-plus',
        'qwen-math-plus-latest',
        'qwen2-1.5b-instruct',
        'qwen2-57b-a14b-instruct',
        'qwen2-72b-instruct',
        'qwen2-7b-instruct',
        'qwen2-0.5b-instruct',
        'qwen-long',
        'qwen-vl-max',
        'qwen-vl-plus',
        'qwen-max-0428',
        'qwen1.5-110b-chat',
        'qwen-72b-chat',
        'qwen-7b-chat',
        'qwen-1.8b-chat',
        'qwen-1.8b-longcontext-chat',
        'qwen1.5-0.5b-chat',
        'codeqwen1.5-7b-chat',
        'qwen-14b-chat',
        'qwen1.5-1.8b-chat',
        'qwen1.5-32b-chat',
        'qwen1.5-72b-chat',
        'qwen-max-longcontext',
        'qwen-max-1201',
        'qwen1.5-14b-chat',
        'qwen-max',
        'qwen-max-0403',
        'qwen-max-0107',
        'qwen-turbo',
        'qwen-plus',
    ]
}

LLM_CONFIGS["groq"] = {
    "base_url":
    "https://api.groq.com/openai/v1",
    "api_key":
    os.getenv("GROQ_ACCESS_KEY"),
    "models": [
        'qwen-qwq-32b',
        'deepseek-r1-distill-qwen-32b',
        'llama-3.3-70b-specdec',
        'deepseek-r1-distill-llama-70b',
        'llama-3.1-8b-instant',
        'whisper-large-v3-turbo',
        'gemma2-9b-it',
        'llama-3.3-70b-versatile',
        'llama-guard-3-8b',
        'mistral-saba-24b',  # 针对小语种的模型
        'llama3-8b-8192',
        'llama-3.2-11b-vision-preview',
        'llama-3.2-3b-preview',
        'llama3-70b-8192',
        'qwen-2.5-32b',
        'llama-3.2-90b-vision-preview',
        'whisper-large-v3',
        'llama-3.2-1b-preview',
        'qwen-2.5-coder-32b',
        'distil-whisper-large-v3-en',
        'allam-2-7b',
    ]
}

LLM_CONFIGS["deepseek"] = {
    "base_url": "https://api.deepseek.com",
    "api_key": os.getenv("DEEPSEEK_ACCESS_KEY"),
    "models": [
        "deepseek-chat",
        "deepseek-reasoner",
    ]
}

LLM_CONFIGS["ollama"] = {
    "base_url":
    "http://localhost:11434/v1/",
    "api_key":
    "ollama",
    "models": [
        'qwq:32b',
        'qwen2.5:32b',
        'deepseek-r1:7b',
        'deepseek-r1:32b',
        'llava:13b',
        'llama3.2-vision:11b',
        'bge-m3:567m',
        'qwen2.5:14b',
        'llava:7b',
        'deepseek-r1:14b',
        'nomic-embed-text:latest',
    ]
}

LLM_CONFIGS["火山方舟"] = {
    "base_url": "https://ark.cn-beijing.volces.com/api/v3",
    "api_key": os.getenv("VOLCANO_ACCESS_KEY"),
    "models": [
        "deepseek-v3-250324",
        "deepseek-r1-250120",
        "deepseek-v3-241226",
    ]
}

LLM_CONFIGS["火山边缘"] = {
    "base_url":
    "https://ai-gateway.vei.volces.com/v1",
    "api_key":
    os.getenv("VOLCANO_EDGE_ACCESS_KEY"),
    "models": [
        # 推理
        "deepseek-reasoner",
        "deepseek-chat",
        # 普通
        "doubao-1.5-lite-32k",
        "doubao-1.5-pro-32k",
        "doubao-pro-128k",
        "doubao-lite-128k",
        "doubao-1.5-pro-256k",
        # 视觉
        "doubao-1.5-vision-pro-32k",
        "AG-ocr-agent",  # "文字识别智能体"
        "doubao-vision-lite-32k",
        "qwen-vl-8k",
        # 分词
        "doubao-embedding-large",
        "doubao-embedding",
        # 音视频
        "doubao-tts",
        "general_v2.0_L",
        'general_v2.0',
        'AG-voice-chat-agent',
        'bigmodel',
        # 智能审核
        'AG-quality-inspection-agent',
        'AG-object-detection-agent',
    ]
}

LLM_CONFIGS["硅基流动"] = {
    "base_url":
    "https://api.siliconflow.cn/v1",
    "api_key":
    os.getenv("SILICONFLOW_ACCESS_KEY"),
    'models': [
        'deepseek-ai/DeepSeek-V3',
        'deepseek-ai/DeepSeek-R1',
        'Pro/deepseek-ai/DeepSeek-V3',
        'Pro/deepseek-ai/DeepSeek-R1',
        'stabilityai/stable-diffusion-xl-base-1.0',
        'stabilityai/stable-diffusion-2-1',
        'THUDM/chatglm3-6b',
        'THUDM/glm-4-9b-chat',
        'Qwen/Qwen2-7B-Instruct',
        'Qwen/Qwen2-1.5B-Instruct',
        'internlm/internlm2_5-7b-chat',
        'BAAI/bge-large-en-v1.5',
        'BAAI/bge-large-zh-v1.5',
        'Pro/Qwen/Qwen2-7B-Instruct',
        'Pro/Qwen/Qwen2-1.5B-Instruct',
        'Pro/THUDM/glm-4-9b-chat',
        'meta-llama/Meta-Llama-3.1-8B-Instruct',
        'Pro/meta-llama/Meta-Llama-3.1-8B-Instruct',
        'meta-llama/Meta-Llama-3.1-70B-Instruct',
        'black-forest-labs/FLUX.1-schnell',
        'black-forest-labs/FLUX.1-dev',
        'FunAudioLLM/SenseVoiceSmall',
        'netease-youdao/bce-embedding-base_v1',
        'BAAI/bge-m3',
        'internlm/internlm2_5-20b-chat',
        'netease-youdao/bce-reranker-base_v1',
        'BAAI/bge-reranker-v2-m3',
        'deepseek-ai/DeepSeek-V2.5',
        'Qwen/Qwen2.5-72B-Instruct',
        'Qwen/Qwen2.5-7B-Instruct',
        'Qwen/Qwen2.5-14B-Instruct',
        'Qwen/Qwen2.5-32B-Instruct',
        'Pro/black-forest-labs/FLUX.1-schnell',
        'Qwen/Qwen2.5-Coder-7B-Instruct',
        'TeleAI/TeleChat2',
        'Pro/Qwen/Qwen2.5-7B-Instruct',
        'Qwen/Qwen2.5-72B-Instruct-128K',
        'Qwen/Qwen2-VL-72B-Instruct',
        'OpenGVLab/InternVL2-26B',
        'Pro/BAAI/bge-m3',
        'Pro/OpenGVLab/InternVL2-8B',
        'Pro/Qwen/Qwen2-VL-7B-Instruct',
        'stabilityai/stable-diffusion-3-5-large',
        'stabilityai/stable-diffusion-3-5-large-turbo',
        'LoRA/Qwen/Qwen2.5-7B-Instruct',
        'fishaudio/fish-speech-1.4',
        'Pro/Qwen/Qwen2.5-Coder-7B-Instruct',
        'LoRA/Qwen/Qwen2.5-72B-Instruct',
        'Qwen/Qwen2.5-Coder-32B-Instruct',
        'Pro/BAAI/bge-reranker-v2-m3',
        'RVC-Boss/GPT-SoVITS',
        'LoRA/RVC-Boss/GPT-SoVITS',
        'genmo/mochi-1-preview',
        'Lightricks/LTX-Video',
        'Qwen/QwQ-32B-Preview',
        'fishaudio/fish-speech-1.5',
        'black-forest-labs/FLUX.1-pro',
        'AIDC-AI/Marco-o1',
        'tencent/HunyuanVideo',
        'LoRA/Qwen/Qwen2.5-14B-Instruct',
        'LoRA/Qwen/Qwen2.5-32B-Instruct',
        'meta-llama/Llama-3.3-70B-Instruct',
        'FunAudioLLM/CosyVoice2-0.5B',
        'LoRA/meta-llama/Meta-Llama-3.1-8B-Instruct',
        'deepseek-ai/deepseek-vl2',
        'Qwen/QVQ-72B-Preview',
        'LoRA/black-forest-labs/FLUX.1-dev',
        'deepseek-ai/Janus-Pro-7B',
        'Qwen/Qwen2.5-VL-72B-Instruct',
        'Pro/Qwen/Qwen2.5-VL-7B-Instruct',
        'Pro/deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B',
        'Pro/deepseek-ai/DeepSeek-R1-Distill-Qwen-7B',
        'Pro/deepseek-ai/DeepSeek-R1-Distill-Llama-8B',
        'deepseek-ai/DeepSeek-R1-Distill-Qwen-14B',
        'deepseek-ai/DeepSeek-R1-Distill-Qwen-32B',
        'deepseek-ai/DeepSeek-R1-Distill-Llama-70B',
        'deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B',
        'deepseek-ai/DeepSeek-R1-Distill-Qwen-7B',
        'deepseek-ai/DeepSeek-R1-Distill-Llama-8B',
        'SeedLLM/Seed-Rice-7B',
        'Kwai-Kolors/Kolors',
        'Qwen/QwQ-32B',
        'Qwen/Qwen2-7B-Instruct/l579qji6kl',
        'Wan-AI/Wan2.1-T2V-14B',
        'Wan-AI/Wan2.1-T2V-14B-Turbo',
        'Wan-AI/Wan2.1-I2V-14B-720P',
        'Wan-AI/Wan2.1-I2V-14B-720P-Turbo',
        'Pro/deepseek-ai/DeepSeek-V3-1226',
    ]
}

LLM_CONFIGS["英伟达"] = {
    "base_url":
    "https://integrate.api.nvidia.com/v1",
    "api_key":
    os.getenv("NVIDIA_ACCESS_KEY"),
    'models': [
        "deepseek-ai/deepseek-r1",
        '01-ai/yi-large',
        'abacusai/dracarys-llama-3.1-70b-instruct',
        'adept/fuyu-8b',
        'ai21labs/jamba-1.5-large-instruct',
        'ai21labs/jamba-1.5-mini-instruct',
        'aisingapore/sea-lion-7b-instruct',
        'baai/bge-m3',
        'baichuan-inc/baichuan2-13b-chat',
        'bigcode/starcoder2-15b',
        'bigcode/starcoder2-7b',
        'databricks/dbrx-instruct',
        'deepseek-ai/deepseek-coder-6.7b-instruct',
        'deepseek-ai/deepseek-r1-distill-llama-8b',
        'deepseek-ai/deepseek-r1-distill-qwen-14b',
        'deepseek-ai/deepseek-r1-distill-qwen-32b',
        'deepseek-ai/deepseek-r1-distill-qwen-7b',
        'google/codegemma-1.1-7b',
        'google/codegemma-7b',
        'google/deplot',
        'google/gemma-2-27b-it',
        'google/gemma-2-2b-it',
        'google/gemma-2-9b-it',
        'google/gemma-2b',
        'google/gemma-3-12b-it',
        'google/gemma-3-1b-it',
        'google/gemma-3-27b-it',
        'google/gemma-3-4b-it',
        'google/gemma-7b',
        'google/paligemma',
        'google/recurrentgemma-2b',
        'google/shieldgemma-9b',
        'ibm/granite-3.0-3b-a800m-instruct',
        'ibm/granite-3.0-8b-instruct',
        'ibm/granite-34b-code-instruct',
        'ibm/granite-8b-code-instruct',
        'ibm/granite-guardian-3.0-8b',
        'igenius/colosseum_355b_instruct_16k',
        'igenius/italia_10b_instruct_16k',
        'institute-of-science-tokyo/llama-3.1-swallow-70b-instruct-v0.1',
        'institute-of-science-tokyo/llama-3.1-swallow-8b-instruct-v0.1',
        'mediatek/breeze-7b-instruct',
        'meta/codellama-70b',
        'meta/llama-3.1-405b-instruct',
        'meta/llama-3.1-70b-instruct',
        'meta/llama-3.1-8b-instruct',
        'meta/llama-3.2-11b-vision-instruct',
        'meta/llama-3.2-1b-instruct',
        'meta/llama-3.2-3b-instruct',
        'meta/llama-3.2-90b-vision-instruct',
        'meta/llama-3.3-70b-instruct',
        'meta/llama2-70b',
        'meta/llama3-70b-instruct',
        'meta/llama3-8b-instruct',
        'microsoft/kosmos-2',
        'microsoft/phi-3-medium-128k-instruct',
        'microsoft/phi-3-medium-4k-instruct',
        'microsoft/phi-3-mini-128k-instruct',
        'microsoft/phi-3-mini-4k-instruct',
        'microsoft/phi-3-small-128k-instruct',
        'microsoft/phi-3-small-8k-instruct',
        'microsoft/phi-3-vision-128k-instruct',
        'microsoft/phi-3.5-mini-instruct',
        'microsoft/phi-3.5-moe-instruct',
        'microsoft/phi-3.5-vision-instruct',
        'microsoft/phi-4-mini-instruct',
        'microsoft/phi-4-multimodal-instruct',
        'mistralai/codestral-22b-instruct-v0.1',
        'mistralai/mamba-codestral-7b-v0.1',
        'mistralai/mathstral-7b-v0.1',
        'mistralai/mistral-7b-instruct-v0.2',
        'mistralai/mistral-7b-instruct-v0.3',
        'mistralai/mistral-large',
        'mistralai/mistral-large-2-instruct',
        'mistralai/mistral-small-24b-instruct',
        'mistralai/mixtral-8x22b-instruct-v0.1',
        'mistralai/mixtral-8x22b-v0.1',
        'mistralai/mixtral-8x7b-instruct-v0.1',
        'nv-mistralai/mistral-nemo-12b-instruct',
        'nvidia/embed-qa-4',
        'nvidia/llama-3.1-nemoguard-8b-content-safety',
        'nvidia/llama-3.1-nemoguard-8b-topic-control',
        'nvidia/llama-3.1-nemotron-51b-instruct',
        'nvidia/llama-3.1-nemotron-70b-instruct',
        'nvidia/llama-3.1-nemotron-70b-reward',
        'nvidia/llama-3.1-nemotron-nano-8b-v1',
        'nvidia/llama-3.2-nv-embedqa-1b-v1',
        'nvidia/llama-3.2-nv-embedqa-1b-v2',
        'nvidia/llama-3.3-nemotron-super-49b-v1',
        'nvidia/llama3-chatqa-1.5-70b',
        'nvidia/llama3-chatqa-1.5-8b',
        'nvidia/mistral-nemo-minitron-8b-8k-instruct',
        'nvidia/mistral-nemo-minitron-8b-base',
        'nvidia/nemoretriever-parse',
        'nvidia/nemotron-4-340b-instruct',
        'nvidia/nemotron-4-340b-reward',
        'nvidia/nemotron-4-mini-hindi-4b-instruct',
        'nvidia/nemotron-mini-4b-instruct',
        'nvidia/neva-22b',
        'nvidia/nv-embed-v1',
        'nvidia/nv-embedcode-7b-v1',
        'nvidia/nv-embedqa-e5-v5',
        'nvidia/nv-embedqa-mistral-7b-v2',
        'nvidia/nvclip',
        'nvidia/usdcode-llama-3.1-70b-instruct',
        'nvidia/vila',
        'qwen/qwen2-7b-instruct',
        'qwen/qwen2.5-7b-instruct',
        'qwen/qwen2.5-coder-32b-instruct',
        'qwen/qwen2.5-coder-7b-instruct',
        'qwen/qwq-32b',
        'rakuten/rakutenai-7b-chat',
        'rakuten/rakutenai-7b-instruct',
        'snowflake/arctic-embed-l',
        'thudm/chatglm3-6b',
        'tiiuae/falcon3-7b-instruct',
        'tokyotech-llm/llama-3-swallow-70b-instruct-v0.1',
        'upstage/solar-10.7b-instruct',
        'writer/palmyra-creative-122b',
        'writer/palmyra-fin-70b-32k',
        'writer/palmyra-med-70b',
        'writer/palmyra-med-70b-32k',
        'yentinglin/llama-3-taiwan-70b-instruct',
        'zyphra/zamba2-7b-instruct',
    ]
}

LLM_CONFIGS["kimi"] = {
    "base_url":
    "https://api.moonshot.cn/v1",
    "api_key":
    os.getenv("MOONSHOT_ACCESS_KEY"),
    'models': [
        "moonshot-v1-8k",
        "moonshot-v1-32k",
        "moonshot-v1-128k",
        'moonshot-v1-8k-vision-preview',
        'moonshot-v1-128k-vision-preview',
        'moonshot-v1-32k-vision-preview',
        'moonshot-v1-auto',
        'kimi-latest',
    ]
}
